# Architecture Drivers — FinSense

## 1. Назначение документа

Данный документ описывает **архитектурные драйверы** системы FinSense — факторы, влияющие на выбор архитектурных решений, декомпозицию системы и технологический стек.

Бизнес-обоснование, ценность для пользователя и экономический эффект описаны в документе `business_case.md`.

## 2. Архитектурный контекст

FinSense — это распределённая событийно-ориентированная система, которая:

* принимает финансовые транзакции,
* выполняет их гибридную классификацию (ML + LLM),
* генерирует персонализированные рекомендации,
* доставляет уведомления пользователю,
* обрабатывает тяжёлые операции асинхронно.

---

## 3. Основные архитектурные драйверы

### 3.1 Производительность

Требования:

* ML-классификация < 50 мс
* Полная обработка транзакции (p95) < 2 секунд
* Отсутствие блокирующих вызовов LLM в REST-потоке

Архитектурные последствия:

* ML вызывается синхронно
* LLM вызывается асинхронно через Kafka
* Тяжёлые операции вынесены за пределы REST-запросов

---

### 3.2 Масштабируемость

Система должна позволять независимое горизонтальное масштабирование:

* Kafka consumer-узлов
* ML-классификатора
* LLM-агентов
* Notification-сервиса

Архитектурные последствия:

* Stateless-сервисы
* Партиционирование Kafka-топиков
* Отсутствие shared-memory
* Независимые deployable-компоненты

---

### 3.3 Надёжность

Система должна гарантировать:

* отсутствие потери транзакций,
* повторную обработку при сбоях,
* идемпотентность обработчиков,
* корректное восстановление после перезапуска.

Архитектурные последствия:

* Kafka как персистентный event log
* Correlation identifiers (`transactionId`, `requestId`)
* Используется модель доставки **at-least-once**.
* Явная state machine транзакции
* Retry-механизмы

---

### 3.4 Стоимость

Использование LLM должно быть ограниченным и контролируемым.

Архитектурные последствия:

* Стратегия ML-first
* Порог confidence для fallback
* Контроль доли LLM-запросов
* Возможность смены LLM-провайдера

---

### 3.5 Заменяемость компонентов

Система должна позволять:

* замену ML-реализации,
* смену LLM-провайдера,
* добавление новых AI-агентов,
* переход к database-per-service модели.

Архитектурные последствия:

* Чёткие границы сервисов
* Интерфейсно-ориентированная архитектура
* Событийное взаимодействие
* Минимальная связность между сервисами

---

### 3.6 Наблюдаемость и аудит

Система должна обеспечивать:

* трассировку жизненного цикла транзакции,
* логирование решений AI,
* измерение latency,
* мониторинг использования LLM.
* измерение доли fallback ML → LLM

Архитектурные последствия:

* Correlation-id во всех событиях
* Structured logging
* Хранение AI-метаданных (JSONB)
* Метрики latency и error rate

---

## 4. Архитектурные ограничения

### 4.1 Технологические ограничения

Фиксированный стек:

* Kotlin / Java
* Gradle / Maven
* Spring Boot
* Apache Kafka
* PostgreSQL
* Docker
* Внешние LLM API
* REST API
* JSON
* JVM-совместимые ML-библиотеки

---

### 4.2 Ограничения среды

* Локальная разработка
* Синтетические данные
* Возможный деплой на VPS

---

## 5. Архитектурные компромиссы

### 5.1 Shared Database vs Database per Service

Выбрано: Общая база Postgres с разными схемами.

Причина:

* Быстрая реализация MVP
* Упрощённое администрирование

Компромисс:

* Более слабая изоляция
* Сложность будущей миграции

---

### 5.2 REST vs Kafka для ML-классификации

Выбрано:

* REST для ML
* Kafka для LLM

Причина:

* ML быстрый и синхронный
* LLM медленный и асинхронный

---

### 5.3 Структурированная схема vs JSONB

Выбрано:

* Реляционная модель для транзакций
* JSONB для AI-ответов

---

## 6. Ключевые архитектурные решения

1. Event-driven architecture на базе Kafka - все значимые изменения состояния публикуются как события
2. Гибридная стратегия ML + LLM - массовая обработка через ML, сложные случаи через LLM
3. Stateless микросервисы - взаимодействие сервисов осуществляется через события или чёткие API-контракты
4. Асинхронная обработка тяжёлых операций
5. Явная state machine транзакции
6. Correlation-id для трассировки
7. Разделение AI-агентов по ответственности
8. Общий Postgres с разными схемами для MVP
9. ReAct-подход (инструментальность агентов) — Financial Coach Agent использует детерминированные инструменты (functions) для получения точных данных и принимает решения на их основе, а не полагается исключительно на знания LLM, .что обеспечивает контролируемость, воспроизводимость и снижение риска галлюцинаций.

---

## 7. Путь эволюции

Возможное развитие архитектуры:

* Database per service
* DLQ и расширенные retry-стратегии
* Distributed tracing (OpenTelemetry)
* Redis-кэширование
* Локальный inference LLM

Текущая архитектура упрощена для MVP, но допускает эволюцию без полной переработки системы.

---